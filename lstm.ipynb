{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "1259\n",
      "[datetime.datetime(2015, 10, 8, 0, 0), 46.015999, 46.144001, 44.262001, 30666000.0, 45.344002]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "with open('TSLA.csv', 'r') as file_data:\n",
    "    csv_reader = csv.reader(file_data)\n",
    "    list_data = []\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            list_data.append([datetime.strptime(row[0], '%Y-%m-%d'),\n",
    "                              float(row[1]),\n",
    "                              float(row[2]),\n",
    "                              float(row[3]),\n",
    "                              float(row[6]),\n",
    "                              float(row[4]),\n",
    "                             ])\n",
    "        except:\n",
    "            print(row)\n",
    "\n",
    "print(len(list_data))\n",
    "print(list_data[0])\n",
    "\n",
    "np.save('tesla.npy', np.array(list_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn.model_selection as sklms\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence 데이터는 에폭 개념이 명확치 않다\n",
    "\n",
    "num_steps = 28\n",
    "ratio_train = 0.7\n",
    "rate_learning = 1e-3\n",
    "\n",
    "num_iters = 10000\n",
    "num_displays = 100\n",
    "size_batch = 64\n",
    "str_file = 'tesla.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259, 6)\n",
      "(1259, 6)\n",
      "(881, 6)\n",
      "(378, 6)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(str_file, allow_pickle=True)\n",
    "print(data.shape)\n",
    "\n",
    "num_data = data.shape[0]\n",
    "dim_data = data.shape[1] - 1 #첫 칼럼 datetime 뺐음\n",
    "mean_closed_price = np.mean(data[:, -1])\n",
    "std_closed_price = np.std(data[:, -1])\n",
    "\n",
    "for ind in range(1, dim_data + 1):\n",
    "    data[:, ind] = (data[:, ind] - np.mean(data[:, ind])) / np.std(data[:, ind])\n",
    "    \n",
    "data_train = data[:int(num_data * ratio_train)]\n",
    "data_test = data[int(num_data * ratio_train):]\n",
    "\n",
    "print(data.shape)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data, size_batch, num_steps):\n",
    "    num_data = data.shape[0]\n",
    "    ind_start = np.random.choice(num_data - num_steps - size_batch + 1, 1)[0]\n",
    "    \n",
    "    list_dates = []\n",
    "    list_samples = []\n",
    "    list_targets = []\n",
    "    \n",
    "    for ind_batch in range(0, size_batch):\n",
    "        cur_index = ind_start + ind_batch\n",
    "        \n",
    "        list_dates.append(data[cur_index + 1: cur_index + num_steps + 1, 0]) # 날짜 정보\n",
    "        list_samples.append(data[cur_index:cur_index + num_steps, 1:]) #\n",
    "        list_targets.append(data[cur_index + 1:cur_index + num_steps + 1, -1]) # 1차원 종가\n",
    "    \n",
    "    samples = np.array(list_samples).astype(np.float32)\n",
    "    targets = np.array(list_targets).astype(np.float32)\n",
    "\n",
    "    return list_dates, samples, targets\n",
    "\n",
    "def recover_prices(prices, mean, std):\n",
    "    return prices * std + mean\n",
    "\n",
    "def plot_prices(dates, by, outputs):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    ax = fig.gca()\n",
    "    ax.plot_date(dates, by, '-')\n",
    "    ax.plot_date(dates, outputs, '-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.layer_fc_pre = tf.keras.layers.Dense(128)\n",
    "        self.layer_lstm = tf.keras.layers.LSTM(256, return_sequences = True)\n",
    "        self.layer_fc_post = tf.keras.layers.Dense(1) #아웃풋 예측\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        #(batch size, num_Steps, 5)\n",
    "        \n",
    "        outputs = self.layer_fc_pre(outputs)\n",
    "        #(batch size, num_Steps, 128)\n",
    "        outputs = self.layer_lstm(outputs)\n",
    "        #(batch size, num_Steps, 256) # 유닛 수, if return_sequences == False: outputs(many to one) = (batchsize, 256)\n",
    "        outputs = self.layer_fc_post(outputs)\n",
    "        #(batch size, num_Steps, 1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              multiple                  768       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  394240    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 395,265\n",
      "Trainable params: 395,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=rate_learning)\n",
    "metrics = tf.keras.metrics.MeanAbsoluteError\n",
    "\n",
    "model.build((None, num_steps, dim_data)) #구체화 하기 힘든 값 None -> batch size\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def step_train(X_batch, by_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds_ = model(X_batch)\n",
    "        loss_ = loss(by_batch, preds_)\n",
    "        \n",
    "    grads_ = tape.gradient(loss_, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads_, model.trainable_weights))\n",
    "    \n",
    "    return loss_\n",
    "\n",
    "@tf.function\n",
    "def step_test(X_batch, by_batch):\n",
    "    preds_ = model(X_batch)\n",
    "    loss_ = loss(by_batch, preds_)\n",
    "    \n",
    "    return loss_, preds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration: Mean squared error 0.061205\n",
      "100 iteration: Mean squared error 0.001459\n",
      "200 iteration: Mean squared error 0.000395\n",
      "300 iteration: Mean squared error 0.000721\n",
      "400 iteration: Mean squared error 0.000176\n",
      "500 iteration: Mean squared error 0.000215\n",
      "600 iteration: Mean squared error 0.001532\n",
      "700 iteration: Mean squared error 0.000382\n",
      "800 iteration: Mean squared error 0.000428\n",
      "900 iteration: Mean squared error 0.000586\n",
      "1000 iteration: Mean squared error 0.000409\n",
      "1100 iteration: Mean squared error 0.000350\n",
      "1200 iteration: Mean squared error 0.000274\n",
      "1300 iteration: Mean squared error 0.001878\n",
      "1400 iteration: Mean squared error 0.001137\n",
      "1500 iteration: Mean squared error 0.000548\n",
      "1600 iteration: Mean squared error 0.001039\n",
      "1700 iteration: Mean squared error 0.000333\n",
      "1800 iteration: Mean squared error 0.001084\n",
      "1900 iteration: Mean squared error 0.000234\n",
      "2000 iteration: Mean squared error 0.000213\n",
      "2100 iteration: Mean squared error 0.000250\n",
      "2200 iteration: Mean squared error 0.000585\n",
      "2300 iteration: Mean squared error 0.000216\n",
      "2400 iteration: Mean squared error 0.001074\n",
      "2500 iteration: Mean squared error 0.000326\n",
      "2600 iteration: Mean squared error 0.000340\n",
      "2700 iteration: Mean squared error 0.000888\n",
      "2800 iteration: Mean squared error 0.000135\n",
      "2900 iteration: Mean squared error 0.000323\n",
      "3000 iteration: Mean squared error 0.000484\n",
      "3100 iteration: Mean squared error 0.000153\n",
      "3200 iteration: Mean squared error 0.000791\n",
      "3300 iteration: Mean squared error 0.000365\n",
      "3400 iteration: Mean squared error 0.000226\n",
      "3500 iteration: Mean squared error 0.000380\n",
      "3600 iteration: Mean squared error 0.000222\n",
      "3700 iteration: Mean squared error 0.000638\n",
      "3800 iteration: Mean squared error 0.000618\n",
      "3900 iteration: Mean squared error 0.000541\n",
      "4000 iteration: Mean squared error 0.000799\n",
      "4100 iteration: Mean squared error 0.000814\n",
      "4200 iteration: Mean squared error 0.000125\n",
      "4300 iteration: Mean squared error 0.000629\n",
      "4400 iteration: Mean squared error 0.000347\n",
      "4500 iteration: Mean squared error 0.000456\n",
      "4600 iteration: Mean squared error 0.000514\n",
      "4700 iteration: Mean squared error 0.000595\n",
      "4800 iteration: Mean squared error 0.000470\n",
      "4900 iteration: Mean squared error 0.000891\n",
      "5000 iteration: Mean squared error 0.000764\n",
      "5100 iteration: Mean squared error 0.003294\n",
      "5200 iteration: Mean squared error 0.000241\n",
      "5300 iteration: Mean squared error 0.000290\n",
      "5400 iteration: Mean squared error 0.000213\n",
      "5500 iteration: Mean squared error 0.000723\n",
      "5600 iteration: Mean squared error 0.000360\n",
      "5700 iteration: Mean squared error 0.000554\n",
      "5800 iteration: Mean squared error 0.000316\n",
      "5900 iteration: Mean squared error 0.000354\n",
      "6000 iteration: Mean squared error 0.000315\n",
      "6100 iteration: Mean squared error 0.000528\n",
      "6200 iteration: Mean squared error 0.000240\n",
      "6300 iteration: Mean squared error 0.000689\n",
      "6400 iteration: Mean squared error 0.000822\n",
      "6500 iteration: Mean squared error 0.000452\n",
      "6600 iteration: Mean squared error 0.000655\n",
      "6700 iteration: Mean squared error 0.000421\n",
      "6800 iteration: Mean squared error 0.000134\n",
      "6900 iteration: Mean squared error 0.000127\n",
      "7000 iteration: Mean squared error 0.000112\n",
      "7100 iteration: Mean squared error 0.000239\n",
      "7200 iteration: Mean squared error 0.000138\n",
      "7300 iteration: Mean squared error 0.000303\n",
      "7400 iteration: Mean squared error 0.000178\n",
      "7500 iteration: Mean squared error 0.000323\n",
      "7600 iteration: Mean squared error 0.000544\n",
      "7700 iteration: Mean squared error 0.000525\n",
      "7800 iteration: Mean squared error 0.000228\n",
      "7900 iteration: Mean squared error 0.000327\n",
      "8000 iteration: Mean squared error 0.000195\n",
      "8100 iteration: Mean squared error 0.000162\n",
      "8200 iteration: Mean squared error 0.000319\n",
      "8300 iteration: Mean squared error 0.000346\n",
      "8400 iteration: Mean squared error 0.000344\n",
      "8500 iteration: Mean squared error 0.000196\n",
      "8600 iteration: Mean squared error 0.000283\n",
      "8700 iteration: Mean squared error 0.000549\n",
      "8800 iteration: Mean squared error 0.000270\n",
      "8900 iteration: Mean squared error 0.000267\n",
      "9000 iteration: Mean squared error 0.000287\n",
      "9100 iteration: Mean squared error 0.000310\n",
      "9200 iteration: Mean squared error 0.000280\n",
      "9300 iteration: Mean squared error 0.000801\n",
      "9400 iteration: Mean squared error 0.000122\n",
      "9500 iteration: Mean squared error 0.000371\n",
      "9600 iteration: Mean squared error 0.000089\n",
      "9700 iteration: Mean squared error 0.000214\n",
      "9800 iteration: Mean squared error 0.000372\n",
      "9900 iteration: Mean squared error 0.000108\n",
      "10000 iteration: Mean squared error 0.000233\n"
     ]
    }
   ],
   "source": [
    "for ind_iter in range(0, num_iters):\n",
    "    _, X_batch, by_batch = sample_data(data_train, size_batch, num_steps)\n",
    "    loss_batch = step_train(X_batch, by_batch)\n",
    "    \n",
    "    if ind_iter == 0 or ind_iter % num_displays == (num_displays - 1):\n",
    "        print('{} iteration: Mean squared error {:.6f}'.format(ind_iter + 1, loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_state() missing 1 required positional argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e6c31166abd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdates_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloss_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean squared error {:.4f} Mean absolute error {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: update_state() missing 1 required positional argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "dates_, X_, by_ = sample_data(data_test, 1, num_steps)\n",
    "loss_, preds_ = step_test(X_, by_)\n",
    "metrics.update_state(by_, preds_)\n",
    "print('Mean squared error {:.4f} Mean absolute error {:.4f}'.format(loss_.numpy(), metrics.result().numpy()))\n",
    "metrics.reset_states()\n",
    "\n",
    "by_ = recover_prices(by_, mean_closed_price, std_closed_price)\n",
    "preds_ = recover_prices(preds_, mean_closed_price, std_closed_price)\n",
    "\n",
    "plot_prices(dates_[0], by_[0], preds_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
